{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc18bc67-ced4-435f-a823-485f13ec7c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c15226-26df-4bea-a8fc-49e5de3c0fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 12500/12500 [00:00<00:00, 15676.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:02<00:00, 5791.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews : 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for label in ['pos', 'neg']:\n",
    "    for file_name in tqdm(os.listdir(f'./aclImdb/train/{label}/')):\n",
    "        with open(os.path.join(f'./aclImdb/train/{label}/', file_name), encoding=\"utf8\") as f:\n",
    "            X.append(f.read())\n",
    "            y.append(label)\n",
    "            \n",
    "print ('Number of reviews :', len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35aeae65-d2f3-4081-9819-a9460671c5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 25000/25000 [00:03<00:00, 7341.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 334691), ('and', 162228), ('a', 161940), ('of', 145326), ('to', 135042), ('is', 106855), ('in', 93028), ('it', 77099), ('i', 75719), ('this', 75190)]\n"
     ]
    }
   ],
   "source": [
    "X = [x.lower() for x in X]\n",
    "X = [''.join([c for c in x if c not in punctuation]) for x in tqdm(X)]\n",
    "\n",
    "words_blob = ' '.join(X)\n",
    "\n",
    "all_words = words_blob.split()\n",
    "\n",
    "words_count = Counter(all_words)\n",
    "\n",
    "words_count_len = len(words_count)\n",
    "sorted_words_count = words_count.most_common(words_count_len)\n",
    "\n",
    "print(sorted_words_count[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec7ddfe-e4c6-452f-97d1-5caccce597a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1), ('and', 2), ('a', 3), ('of', 4), ('to', 5), ('is', 6), ('in', 7), ('it', 8), ('i', 9), ('this', 10)]\n"
     ]
    }
   ],
   "source": [
    "word_to_idx = {word: idx+1 for idx, (word, _) in enumerate(sorted_words_count)}\n",
    "print(list(word_to_idx.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "751ef20d-f893-492b-82e9-c6bbdafb86d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell highs satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high a classic line inspector im here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isnt\n",
      "\n",
      "[22572, 321, 6, 3, 1077, 219, 8, 2082, 30, 1, 166, 61, 14, 46, 80, 5581, 42, 399, 118, 135, 14, 4883, 55, 4980, 147, 7, 1, 4941, 6023, 479, 69, 5, 255, 11, 22572, 17217, 1970, 6, 72, 2356, 5, 638, 70, 6, 4883, 1, 26241, 5, 2031, 10833, 1, 5884, 1421, 36, 68, 67, 204, 140, 64, 1215, 4883, 21183, 1, 43770, 4, 1, 218, 902, 31, 2922, 69, 4, 1, 4706, 9, 671, 2, 64, 1421, 50, 9, 207, 1, 382, 7, 59, 3, 1473, 3614, 774, 5, 3561, 186, 1, 399, 9, 1191, 14623, 30, 321, 3, 349, 362, 2960, 141, 131, 5, 9055, 28, 4, 122, 4883, 1473, 2410, 5, 22572, 321, 9, 515, 11, 105, 1462, 4, 55, 580, 102, 11, 22572, 321, 6, 233, 8881, 48, 3, 2285, 11, 8, 206]\n"
     ]
    }
   ],
   "source": [
    "X_encoded = []\n",
    "\n",
    "for x in X:\n",
    "    x_encoded = [word_to_idx[word] for word in x.split()]\n",
    "    X_encoded.append(x_encoded)\n",
    "\n",
    "y_encoded = [1 if label =='pos' else 0 for label in y]\n",
    "y_encoded = np.array(y_encoded, dtype='float32')\n",
    "\n",
    "print(X[0])\n",
    "print()\n",
    "print (X_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "867ef540-e3fa-4166-b822-1421f0ab232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(X, sequence_length):\n",
    "    X_padded = np.zeros((len(X), sequence_length), dtype = int)\n",
    "    \n",
    "    for idx, x in enumerate(X):\n",
    "        x_len = len(x)\n",
    "        \n",
    "        if x_len <= sequence_length:\n",
    "            zeroes = list(np.zeros(sequence_length - x_len))\n",
    "            new_x = zeroes + x\n",
    "        elif x_len > sequence_length:\n",
    "            new_x = x[0: sequence_length]\n",
    "        \n",
    "        X_padded[idx,:] = np.array(new_x)\n",
    "    \n",
    "    return X_padded\n",
    "\n",
    "sequence_length = 512\n",
    "X_padded = pad_sequence(X_encoded, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c64f81f-0b19-4b5e-8bbe-e3e09ad31367",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = 0.75\n",
    "X_len = len(X_padded)\n",
    "\n",
    "train_X = X_padded[:int(train_val_split * X_len)]\n",
    "train_y = y_encoded[:int(train_val_split * X_len)]\n",
    "\n",
    "val_X = X_padded[int(train_val_split * X_len):]\n",
    "val_y = y_encoded[int(train_val_split * X_len):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0cf256-7beb-44bf-9b9a-a7180f4149d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(train_X).to(device), torch.from_numpy(train_y).to(device))\n",
    "val_dataset = TensorDataset(torch.from_numpy(val_X).to(device), torch.from_numpy(val_y).to(device))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8ba106-6785-4a17-a02b-45a786f36c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Input size:  torch.Size([32, 512])\n",
      "Example Input:\n",
      " tensor([[   29,    31,    57,  ...,    91,    22,    23],\n",
      "        [    0,     0,     0,  ...,    12,     1,  8247],\n",
      "        [    0,     0,     0,  ...,  1482,   939, 15257],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,   311,     8,     6],\n",
      "        [    0,     0,     0,  ...,    99,  1215,   131],\n",
      "        [    0,     0,     0,  ...,  1982,     8,   131]], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "\n",
      "Example Output size:  torch.Size([32])\n",
      "Example Output:\n",
      " tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "train_data_iter = iter(train_dataloader)\n",
    "X_example, y_example = next(train_data_iter)\n",
    "print('Example Input size: ', X_example.size()) \n",
    "print('Example Input:\\n', X_example)\n",
    "print()\n",
    "print('Example Output size: ', y_example.size()) \n",
    "print('Example Output:\\n', y_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04c28bf-3fad-4a71-b342-2cd97ec7ae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dimension, embedding_dimension, hidden_dimension, output_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(input_dimension, embedding_dimension)  \n",
    "        self.rnn_layer = nn.RNN(embedding_dimension, hidden_dimension, num_layers=1)\n",
    "        self.fc_layer = nn.Linear(hidden_dimension, output_dimension)\n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        # sequence shape = (sequence_length, batch_size)\n",
    "        embedding = self.embedding_layer(sequence)  \n",
    "        # embedding shape = [sequence_length, batch_size, embedding_dimension]\n",
    "        output, hidden_state = self.rnn_layer(embedding)\n",
    "        # output shape = [sequence_length, batch_size, hidden_dimension]\n",
    "        # hidden_state shape = [1, batch_size, hidden_dimension]\n",
    "        final_output = self.fc_layer(hidden_state[-1,:,:].squeeze(0))      \n",
    "        return final_output\n",
    "    \n",
    "input_dimension = len(word_to_idx) + 1 # +1 to account for padding\n",
    "embedding_dimension = 100\n",
    "hidden_dimension = 32\n",
    "output_dimension = 1\n",
    "\n",
    "model = Model(input_dimension, embedding_dimension, hidden_dimension, output_dimension)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61d7f8ae-3409-483b-b9c6-fd3f22d20aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(predictions, ground_truth):\n",
    "    rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
    "    success = (rounded_predictions == ground_truth).float() \n",
    "    accuracy = success.sum() / len(success)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e30d5f50-d204-4ce4-bf26-bd75cf1751f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optim, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.train()\n",
    "    \n",
    "    for sequence, label in dataloader:\n",
    "        optim.zero_grad()     \n",
    "        preds = model(sequence.T).squeeze()\n",
    "        \n",
    "        loss_curr = loss_func(preds, label)\n",
    "        accuracy_curr = accuracy_metric(preds, label)\n",
    "        \n",
    "        loss_curr.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        loss += loss_curr.item()\n",
    "        accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(dataloader), accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92c11548-ca73-415f-b0a1-2918b648b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequence, label in dataloader:\n",
    "            \n",
    "            preds = model(sequence.T).squeeze()\n",
    "            \n",
    "            loss_curr = loss_func(preds, label)   \n",
    "            accuracy_curr = accuracy_metric(preds, label)\n",
    "\n",
    "            loss += loss_curr.item()\n",
    "            accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(dataloader), accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb768dc4-37d4-48ac-b0f4-8d4c78888a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1 | time elapsed: 9.691661834716797s\n",
      "training loss: 0.622 | training accuracy: 66.86%\n",
      "validation loss: 1.093 |  validation accuracy: 17.23%\n",
      "\n",
      "epoch number: 2 | time elapsed: 8.412366151809692s\n",
      "training loss: 0.541 | training accuracy: 73.25%\n",
      "validation loss: 0.841 |  validation accuracy: 51.50%\n",
      "\n",
      "epoch number: 3 | time elapsed: 8.211649417877197s\n",
      "training loss: 0.448 | training accuracy: 79.72%\n",
      "validation loss: 1.030 |  validation accuracy: 47.17%\n",
      "\n",
      "epoch number: 4 | time elapsed: 8.301143646240234s\n",
      "training loss: 0.385 | training accuracy: 83.66%\n",
      "validation loss: 0.861 |  validation accuracy: 59.28%\n",
      "\n",
      "epoch number: 5 | time elapsed: 8.100085973739624s\n",
      "training loss: 0.318 | training accuracy: 87.03%\n",
      "validation loss: 0.862 |  validation accuracy: 59.38%\n",
      "\n",
      "epoch number: 6 | time elapsed: 8.156765222549438s\n",
      "training loss: 0.284 | training accuracy: 88.78%\n",
      "validation loss: 0.547 |  validation accuracy: 75.94%\n",
      "\n",
      "epoch number: 7 | time elapsed: 8.077811479568481s\n",
      "training loss: 0.245 | training accuracy: 90.66%\n",
      "validation loss: 1.031 |  validation accuracy: 61.64%\n",
      "\n",
      "epoch number: 8 | time elapsed: 8.32004189491272s\n",
      "training loss: 0.190 | training accuracy: 93.18%\n",
      "validation loss: 0.985 |  validation accuracy: 66.31%\n",
      "\n",
      "epoch number: 9 | time elapsed: 8.91414499282837s\n",
      "training loss: 0.174 | training accuracy: 93.92%\n",
      "validation loss: 1.129 |  validation accuracy: 60.06%\n",
      "\n",
      "epoch number: 10 | time elapsed: 8.73631238937378s\n",
      "training loss: 0.174 | training accuracy: 93.61%\n",
      "validation loss: 1.298 |  validation accuracy: 60.81%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "\n",
    "    time_start = time.time()\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, train_dataloader, optim, loss_func)\n",
    "    val_loss, val_accuracy = validate(model, val_dataloader, loss_func)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_delta = time_end - time_start  \n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'rnn_model.pt')\n",
    "    \n",
    "    print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
    "    print(f'training loss: {train_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
    "    print(f'validation loss: {val_loss:.3f} |  validation accuracy: {val_accuracy*100:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4713b234-ab6e-4838-823b-0209a12374ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([c for c in sentence if c not in punctuation])\n",
    "    tokenized = [word_to_idx.get(token, 0) for token in sentence.split()]\n",
    "    tokenized = np.pad(tokenized, (512 - len(tokenized), 0), 'constant')\n",
    "    \n",
    "    model_input = torch.LongTensor(tokenized).to(device)\n",
    "    model_input = model_input.unsqueeze(1)\n",
    "    pred = torch.sigmoid(model(model_input))\n",
    "    \n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "428a240d-c4cd-4674-a1e8-b12df974c647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013179408386349678\n",
      "0.010017585009336472\n",
      "0.9989331364631653\n",
      "0.9773225784301758\n"
     ]
    }
   ],
   "source": [
    "print(classify(model, \"This film is horrible\"))\n",
    "print(classify(model, \"Director tried too hard but this film is bad\"))\n",
    "print(classify(model, \"This film will be houseful for weeks\"))\n",
    "print(classify(model, \"I just really loved the movie\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f0896-3145-41d2-b0d5-ce8c16b16470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
